{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT from scratch",
      "provenance": [],
      "authorship_tag": "ABX9TyPZSIj2NkfKNfX/yOf6ZhGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singhsidhukuldeep/training-BERT-from-scratch/blob/main/BERT_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwhNQA6QvN7n"
      },
      "source": [
        "# Reference: https://huggingface.co/blog/how-to-train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5CrOLE7aJv",
        "outputId": "7ed2251a-6f6d-4de5-f66b-af358f86860f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# https://huggingface.co/nlp/viewer/?dataset=wiki_split\n",
        "\n",
        "# https://huggingface.co/datasets/wiki_split\n",
        "\n",
        "# 1 Million lines/ 170 MB\n",
        "\n",
        "!wget -c https://github.com/google-research-datasets/wiki-split/raw/master/train.tsv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 11:09:21--  https://github.com/google-research-datasets/wiki-split/raw/master/train.tsv.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/google-research-datasets/wiki-split/master/train.tsv.zip [following]\n",
            "--2020-11-02 11:09:21--  https://raw.githubusercontent.com/google-research-datasets/wiki-split/master/train.tsv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96439435 (92M) [application/zip]\n",
            "Saving to: ‘train.tsv.zip’\n",
            "\n",
            "train.tsv.zip       100%[===================>]  91.97M   143MB/s    in 0.6s    \n",
            "\n",
            "2020-11-02 11:09:23 (143 MB/s) - ‘train.tsv.zip’ saved [96439435/96439435]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TQFX-I-SVz",
        "outputId": "c46f5c2d-bd90-458b-dcaf-b017919306d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls\n",
        "!unzip train.tsv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  train.tsv.zip\n",
            "Archive:  train.tsv.zip\n",
            "  inflating: train.tsv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFMMz8wIreTX",
        "outputId": "dcba78f0-7671-4fc2-ac38-71e8659ee065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!head -10 train.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' '' As she translates from one language to another , she tries to find the appropriate wording and context in English that would correspond to the work in Spanish her poems and stories started to have differing meanings in their respective languages .\t' '' As she translates from one language to another , she tries to find the appropriate wording and context in English that would correspond to the work in Spanish . <::::> Ergo , her poems and stories started to have differing meanings in their respective languages .\n",
            "' '' BDSM is solely based on consensual activities , and based on its system and laws , the concepts presented by de Sade are not agreed upon the BDSM culture , even though they are sadistic in nature .\t' '' BDSM is solely based on consensual activities , and based on its system and laws . <::::> The concepts presented by de Sade are not in accordance with the BDSM culture , even though they are sadistic in nature .\n",
            "' '' Critics criticized the use of the disputed figures by conservative organizations ; for example , The Traditional Values Coalition used the article to urge the Centers for Disease Control to cut down on its AIDS funding .\t' '' Critics criticized the use of the disputed figures by conservative organizations . <::::> For example , The Traditional Values Coalition used the article to urge the Centers for Disease Control to cut down on its AIDS funding .\n",
            "' '' Do Re Mi '' ' is a song by Kurt Cobain of the band Nirvana , and is believed to be one of the final songs he wrote before his apparent suicide in April 1994 .\t' '' Do Re Mi '' ' is a song by Kurt Cobain , lead singer and guitarist of the American rock band Nirvana . <::::> It is believed to be one of the final songs he wrote before his apparent suicide in April 1994 .\n",
            "' '' For Robert Price '' docetism '' , together with '' encratism '' , '' Gnosticism '' and '' adoptionism '' hrist was so divine that he could not have been human , since God lacked a material body , which therefore could not physically suffer .\t' '' For Robert Price '' docetism '' , together with '' encratism '' , '' Gnosticism '' and '' adoptionism '' , has been employed '' far beyond what historically descriptive usage would allow '' . <::::> In one version , as in Marcionism , Christ was so divine that he could not have been human , since God lacked a material body , which therefore could not physically suffer .\n",
            "' '' He was the fourth of the nine children of Jeremiah Scotland Allison and his wife , Mariah Ruth Brown and his father was a Presbyterian minister , who raised cattle and sheep to support his family .\t' '' He was the fourth of the nine children of Jeremiah Scotland Allison and his wife , Mariah Ruth Brown . <::::> His father was a Presbyterian minister who raised cattle and sheep to support his family .\n",
            "' '' Her mother worked as a seamstress and her father was a German immigrant , and Autumn says that she did not share a close relationship with him .\t' '' Her mother worked as a seamstress and Autumn says she is a descendant from the Liddell family . <::::> Her father was a German immigrant , and Autumn says that she did not share a close relationship with him .\n",
            "' '' Her mother worked as a seamstress and her father was a German immigrant ; Autumn says that she did not share a close relationship with him .\t' '' Her mother worked as a seamstress and Autumn says she is a descendant from the Liddell family . <::::> Her father was a German immigrant , and Autumn says that she did not share a close relationship with him .\n",
            "' '' In 2009 , a New Jersey federal judge rejected the RNC 's request ; this ruling was upheld by the U.S. Court of Appeals for the Third Circuit in 2012 , and the Supreme Court declined to hear the RNC 's appeal in 2013 .\t' '' In 2009 , a New Jersey federal judge rejected the RNC 's request to vacate the consent decree , and this ruling was unanimously affirmed by the U.S. Court of Appeals for the Third Circuit in 2012 . <::::> The Supreme Court declined to hear the RNC 's appeal in 2013 .\n",
            "' '' In a more recent case , '' Givhan v. Western Line Consolidated School District '' , '' Givhan v. Western Line Consolidated School District '' , .\t' '' In a more recent case , '' Givhan v. Western Line Consol . <::::> School Dist. '' , '' Givhan v. Western Line Consolidated School District '' , .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_15N4SdxBc8w"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.tsv', sep='\\t', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM4rB4IqrZ54",
        "outputId": "3afceac8-19f1-4a6b-fa8d-9931df956a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>' '' As she translates from one language to an...</td>\n",
              "      <td>' '' As she translates from one language to an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>' '' BDSM is solely based on consensual activi...</td>\n",
              "      <td>' '' BDSM is solely based on consensual activi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>' '' Critics criticized the use of the dispute...</td>\n",
              "      <td>' '' Critics criticized the use of the dispute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>' '' Do Re Mi '' ' is a song by Kurt Cobain of...</td>\n",
              "      <td>' '' Do Re Mi '' ' is a song by Kurt Cobain , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>' '' For Robert Price '' docetism '' , togethe...</td>\n",
              "      <td>' '' For Robert Price '' docetism '' , togethe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0                                                  1\n",
              "0  ' '' As she translates from one language to an...  ' '' As she translates from one language to an...\n",
              "1  ' '' BDSM is solely based on consensual activi...  ' '' BDSM is solely based on consensual activi...\n",
              "2  ' '' Critics criticized the use of the dispute...  ' '' Critics criticized the use of the dispute...\n",
              "3  ' '' Do Re Mi '' ' is a song by Kurt Cobain of...  ' '' Do Re Mi '' ' is a song by Kurt Cobain , ...\n",
              "4  ' '' For Robert Price '' docetism '' , togethe...  ' '' For Robert Price '' docetism '' , togethe..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro7VoQqqqeER",
        "outputId": "3ee75aaf-54e4-4c81-c736-748c67b17f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "clr = lambda x: x.replace(\"' '' \", '')\n",
        "df[0] = df[0].apply(clr)\n",
        "df.drop([1], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As she translates from one language to another...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BDSM is solely based on consensual activities ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Critics criticized the use of the disputed fig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do Re Mi '' ' is a song by Kurt Cobain of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For Robert Price '' docetism '' , together wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  As she translates from one language to another...\n",
              "1  BDSM is solely based on consensual activities ...\n",
              "2  Critics criticized the use of the disputed fig...\n",
              "3  Do Re Mi '' ' is a song by Kurt Cobain of the ...\n",
              "4  For Robert Price '' docetism '' , together wit..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp7RBO3CCegZ"
      },
      "source": [
        "df[0].to_csv('train.txt', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUpkhzEGrrnI",
        "outputId": "62735dcf-e5c7-4ed5-b33f-4ee60cbf0f4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "# !pip uninstall -y tensorflow\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Successfully uninstalled tensorflow-2.3.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-iwcm20s2\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-iwcm20s2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1285611 sha256=71918956a1daa76f516c2781f3ec14812204bd30adb93d4ca5b9cfae591ad77b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9er4jrfi/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=db809b6f398987e0d7d91846e6962950f7e2851c249d80dbeab14d764a91c17f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n",
            "tokenizers                    0.9.2          \n",
            "transformers                  3.4.0          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVowJ1PLu229",
        "outputId": "58998cb8-a7ce-48c4-d14b-f624bafa1d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time \n",
        "from pathlib import Path\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train(files=paths, vocab_size=20_000, min_frequency=2, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 54s, sys: 991 ms, total: 3min 55s\n",
            "Wall time: 2min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4h_ZMevEEA",
        "outputId": "74cac375-94ee-4922-c62c-3b0435187d15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir BERTboi\n",
        "tokenizer.save_model(\"BERTboi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BERTboi/vocab.json', 'BERTboi/merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIzzKf0ivRns"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./BERTboi/vocab.json\",\n",
        "    \"./BERTboi/merges.txt\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KtcT3dyvYmi"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaFwOxowvhkz",
        "outputId": "5187b710-46ea-4df6-ea40-7ab83b4a246e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.encode(\"This is America\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=5, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxCjKzVgvn70",
        "outputId": "0deeeb5c-d794-4407-887f-a0f89efba2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.encode(\"This is America\").tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'This', 'Ġis', 'ĠAmerica', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ljBfbB-vznK",
        "outputId": "fc0545a1-5348-4697-966e-621eb47e1a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov  2 11:37:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzQNuiRev3Fy",
        "outputId": "a43bdf63-ef52-43fa-a1c5-c54128c79e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUL0zq3Gv4zn"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=20_000,\n",
        "    max_position_embeddings=400,\n",
        "    num_attention_heads=2,\n",
        "    num_hidden_layers=3,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HDCGWAjwFqj"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"./BERTboi\", max_len=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK0e0WfqwMYm"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqKrpjESwPTH",
        "outputId": "9c71b7f2-2148-4e11-98d9-f62c41779cab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.num_parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37545248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9zQKDCowRqq",
        "outputId": "93c0eee0-ba19-482f-b10f-74326c7a17d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"./train.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 3s, sys: 4.37 s, total: 3min 7s\n",
            "Wall time: 1min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbNUiLTxwelH"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KsXBdhwrEg",
        "outputId": "45ad3cb2-c2b0-4cd0-d121-96174fb03a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./BERTboi\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=sc,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:281: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDR5T-CNwwjR",
        "outputId": "07533ccd-a506-46d7-f34e-377011c8c9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='15468' max='15468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15468/15468 1:31:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.355470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>6.859652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>6.705604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.595646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>6.494686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.357398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>6.208945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.054441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>5.898809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.761188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>5.639090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>5.543141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>5.435977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>5.365102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>5.282477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>5.229453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>5.163445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>5.131953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>5.094766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>5.069383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>5.030133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>4.996297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>4.972898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>4.944047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>4.934000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>4.929859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>4.895562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>4.896172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>4.888906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>4.878281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 51min 14s, sys: 39min 16s, total: 1h 30min 30s\n",
            "Wall time: 1h 31min 1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15468, training_loss=5.5329965493276445)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIy8ZB2VwyPO"
      },
      "source": [
        "trainer.save_model(\"./BERTboi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-FsqDHtw3yz",
        "outputId": "bca3237a-2da7-4251-e848-f83b879b601b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./BERTboi\",\n",
        "    tokenizer=\"./BERTboi\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at ./BERTboi and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsxGEA7Gw9T2",
        "outputId": "a7bf89f8-9240-444f-84b7-a7f734cf2dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fill_mask(\"Apples are good for <mask>\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.012861344031989574,\n",
              "  'sequence': '<s>Apples are good for example</s>',\n",
              "  'token': 2438,\n",
              "  'token_str': 'Ġexample'},\n",
              " {'score': 0.008665323257446289,\n",
              "  'sequence': '<s>Apples are good for them</s>',\n",
              "  'token': 821,\n",
              "  'token_str': 'Ġthem'},\n",
              " {'score': 0.0066885086707770824,\n",
              "  'sequence': '<s>Apples are good for people</s>',\n",
              "  'token': 1136,\n",
              "  'token_str': 'Ġpeople'},\n",
              " {'score': 0.006021216511726379,\n",
              "  'sequence': '<s>Apples are good for different</s>',\n",
              "  'token': 1615,\n",
              "  'token_str': 'Ġdifferent'},\n",
              " {'score': 0.005974438972771168,\n",
              "  'sequence': '<s>Apples are good for.\"</s>',\n",
              "  'token': 293,\n",
              "  'token_str': 'Ġ.\"'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaKx2zNZGot3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}